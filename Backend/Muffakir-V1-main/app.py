# Muffakir V3
import streamlit as st
import os
from langchain.document_loaders import DirectoryLoader
from AnswerGenerator import *
from ChromaDBManager import *
from DocumentRetriever import *
from EmbeddingProvider import *
from LLMProvider import *
from PromptManager import *
from QueryTransformer import *
from RAGGenerationPipeline import *
from RAGPipelineManager import *
from RetrieveMethods import *
from TextProcessor import *
from api_keys import api_keys_qroq, api_keys_together,api_keys_open_router
from Reranker import *
from HallucinationsCheck import *
from QuizGeneration import *
from Search import Search
from UploadFile import UploadFile  # Import the UploadFile class

# Paths for file upload
new_db_path = r"D:\College\Level 4\Graduation Project\Muffakir-Web-V5\Muffakir-Web-V2\Backend\Muffakir-V1-main\upload"
output_dir = r"D:\College\Level 4\Graduation Project\Muffakir-Web-V5\Muffakir-Web-V2\Backend\Muffakir-V1-main\TXT"
default_db_path = r"D:\College\Level 4\Graduation Project\Muffakir-Web-V5\Muffakir-Web-V2\Backend\Muffakir-V1-main\DB"

def initialize_rag_manager(db_path: str, collection_name: str = "Book"):
    embedding_model_name = "mohamed2811/Muffakir_Embedding"

    llm_provider = LLMProvider(
        provider_name="together",
        temperature=0,
        api_keys=api_keys_together,
        model="meta-llama/Llama-3.3-70B-Instruct-Turbo"
    )
    
    prompt_manager = PromptManager()
    query_transformer = QueryTransformer(llm_provider, prompt_manager, prompt="query_rewrite")
    query_processor = QueryDocumentProcessor(llm_provider, prompt_manager)
    hallucination = HallucinationsCheck(llm_provider, prompt_manager)

    return RAGPipelineManager(
        db_path=db_path,
        model_name=embedding_model_name,
        query_transformer=query_transformer,
        llm_provider=llm_provider,
        prompt_manager=prompt_manager,
        k=5,
        retrive_method="similarity_search",
        query_processor=query_processor,
        hallucination=hallucination,
        collection_name=collection_name  # Added collection_name parameter
    )

@st.cache_resource
def get_rag_manager(db_path: str = default_db_path, collection_name: str = "Book"):
    return initialize_rag_manager(db_path, collection_name)

# Initialize Deep Search
def initialize_search():
    llm_provider = LLMProvider(
        provider_name="together",
        temperature=0,
        api_keys=api_keys_together,
        model="meta-llama/Llama-3.3-70B-Instruct-Turbo"
    )
    prompt_manager = PromptManager()
    params = {
        "maxDepth": 2,
        "timeLimit": 30,
        "maxUrls": 5
    }
    return Search(
        api_key="fc-a30e949feb1545849b665093e6fe0e87",
        llm_provider=llm_provider,
        prompt_manager=prompt_manager,
        params=params
    )

@st.cache_resource
def get_search_instance():
    return initialize_search()

# Initialize Quiz Generator
def initialize_quiz(db_path: str = default_db_path, collection_name: str = "Book"):
    llm_provider = LLMProvider(
        provider_name="together",
        temperature=0,
        api_keys=api_keys_together,
        model="meta-llama/Llama-3.3-70B-Instruct-Turbo"
    )
    prompt_manager = PromptManager()
    rag_manager = get_rag_manager(db_path, collection_name)
    doc = DocumentRetriever(rag_manager)
    return QuizGeneration(llm_provider, prompt_manager, retriever=doc)

@st.cache_resource
def get_quiz_instance(db_path: str = default_db_path, collection_name: str = "Book"):
    return initialize_quiz(db_path, collection_name)

# Chat UI Styles
st.markdown(
    """
    <style>
    .chat-container {
        display: flex;
        flex-direction: column;
        gap: 10px;
        margin: 10px 0;
    }
    .message {
        padding: 10px 15px;
        border-radius: 12px;
        max-width: 70%;
        word-wrap: break-word;
    }
    .user-message {
        background-color: #DCF8C6;
        align-self: flex-end;
        text-align: right;
    }
    .assistant-message {
        background-color: #FFFFFF;
        align-self: flex-start;
        text-align: left;
        border: 1px solid #e0e0e0;
    }
    .file-upload-section {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        margin: 20px 0;
    }
    .tab-content {
        padding: 20px 0;
    }
    </style>
    """, unsafe_allow_html=True
)

def display_chat_history():
    """Display chat history"""
    st.markdown('<div class="chat-container">', unsafe_allow_html=True)
    for msg in st.session_state.chat_history:
        if msg["sender"] == "user":
            st.markdown(
                f'<div class="message user-message"><strong>ğŸ‘¤ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:</strong> {msg["message"]}</div>',
                unsafe_allow_html=True
            )
        else:
            st.markdown(
                f'<div class="message assistant-message"><strong>ğŸ¤– Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯:</strong> {msg["message"]}</div>',
                unsafe_allow_html=True
            )
    st.markdown('</div>', unsafe_allow_html=True)

def get_final_search(search_result,query):
    """Get the final search results."""
    llm_provider = LLMProvider(
        provider_name="together",
        temperature=0,
        api_keys=api_keys_together,
        model="meta-llama/Llama-3.3-70B-Instruct-Turbo"
    )
    prompt_manager = PromptManager()
    llm = llm_provider.get_llm()
    final_analysis=search_result["data"].get("finalAnalysis", "Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªØ­Ù„ÙŠÙ„ Ù…ØªØ§Ø­.")
    generation_prompt = prompt_manager.get_prompt("generation")

    prompt = generation_prompt.format(
                context=final_analysis,
                question=query
                )

    response = llm.invoke(prompt)

    return response.content

def main():
    st.title("Muffakir - Legal AI Assistant")
    st.write("ğŸ”¹ Ù…Ø³Ø§Ø¹Ø¯ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø°ÙƒÙŠ ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙÙŠ Ø§Ù„Ø¨Ø­Ø« ÙˆØ§Ù„Ø¥Ø¬Ø§Ø¨Ø©.")

    # Initialize session states
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    
    if "quiz_results" not in st.session_state:
        st.session_state.quiz_results = None
        
    if "db_path" not in st.session_state:
        st.session_state.db_path = default_db_path
        
    if "collection_name" not in st.session_state:
        st.session_state.collection_name = "Book"
        
    if "using_uploaded_file" not in st.session_state:
        st.session_state.using_uploaded_file = False

    # Create tabs for different functionalities
    tab1, tab2 = st.tabs(["ğŸ’¬ Ù…Ø­Ø§Ø¯Ø«Ø©", "ğŸ“¤ Ø±ÙØ¹ Ù…Ù„Ù"])
    
    with tab1:
        st.markdown('<div class="tab-content">', unsafe_allow_html=True)
        
        # Show current data source info
        if st.session_state.using_uploaded_file:
            st.info(f"ğŸ”„ ØªØ³ØªØ®Ø¯Ù… Ø­Ø§Ù„ÙŠÙ‹Ø§: Ù…Ù„Ù ØªÙ… ØªØ­Ù…ÙŠÙ„Ù‡")
            if st.button("ğŸ”™ Ø§Ù„Ø¹ÙˆØ¯Ø© Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©"):
                st.session_state.db_path = default_db_path
                st.session_state.collection_name = "Book"
                st.session_state.using_uploaded_file = False
                st.session_state.chat_history = []  # Reset chat history
                st.rerun()
    
        # Load dependencies based on current database settings
        rag_manager = get_rag_manager(st.session_state.db_path, st.session_state.collection_name)
        search_instance = get_search_instance()

        # User input
        user_input = st.text_input("ğŸ“ Ø§Ø³Ø£Ù„ Ø³Ø¤Ø§Ù„Ø§Ù‹ Ù‚Ø§Ù†ÙˆÙ†ÙŠÙ‹Ø§:")

        # Action buttons
        col1, col2, col3 = st.columns([1, 1, 1])
        
        with col1:
            send_button = st.button("ğŸ’¬ Ø¥Ø±Ø³Ø§Ù„")
        with col2:
            search_button = st.button("ğŸ” Ø¨Ø­Ø« Ø¹Ù…ÙŠÙ‚")
        with col3:
            quiz_button = st.button("ğŸ“ ØªÙˆÙ„ÙŠØ¯ Ø§Ø®ØªØ¨Ø§Ø±")

        # Quiz generation
        if quiz_button and user_input:
            try:
                quiz = get_quiz_instance(st.session_state.db_path, st.session_state.collection_name)
                st.session_state.quiz_results = quiz.generate_quiz(query=user_input)
            except Exception as e:
                st.error(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {str(e)}")

        # Quiz display and interaction
        if st.session_state.quiz_results and st.session_state.quiz_results["questions"]:
            st.subheader("ğŸ“š Ø§Ø®ØªØ¨Ø§Ø± ØªÙØ§Ø¹Ù„ÙŠ")
            
            # Add reset button
            if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±"):
                st.session_state.quiz_results = None
                st.rerun()

            for i, (question, options, correct_answer, explanation) in enumerate(
                zip(
                    st.session_state.quiz_results["questions"], 
                    st.session_state.quiz_results["options"], 
                    st.session_state.quiz_results["correct_answers"], 
                    st.session_state.quiz_results["explanations"]
                )
            ):
                st.markdown(f"**Ø³Ø¤Ø§Ù„ {i+1}:** {question}")
                
                # Create radio buttons with persisted state
                option_letters = ["Ø£", "Ø¨", "Ø¬", "Ø¯"]
                selected_index = st.session_state.get(f"selected_option_{i}", None)
                user_answer = st.radio(
                    "Ø§Ø®ØªØ± Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„ØµØ­ÙŠØ­Ø©:",
                    options,
                    key=f"quiz_{i}_options",
                    index=selected_index
                )
                
                # Store selection in session state
                if user_answer:
                    st.session_state[f"selected_option_{i}"] = options.index(user_answer)
                
                # Show answer button
                if st.button(f"Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù„Ù„Ø³Ø¤Ø§Ù„ {i+1}", key=f"show_answer_{i}"):
                    try:
                        # Handle different answer formats
                        if correct_answer in option_letters:
                            correct_index = option_letters.index(correct_answer)
                        elif correct_answer.upper() in ['A', 'B', 'C', 'D']:
                            correct_index = ord(correct_answer.upper()) - ord('A')
                        elif len(correct_answer) == 1 and 'Ø£' <= correct_answer <= 'Ø¯':
                            arabic_map = {'Ø£': 0, 'Ø¨': 1, 'Ø¬': 2, 'Ø¯': 3}
                            correct_index = arabic_map.get(correct_answer, 0)
                        else:
                            try:
                                correct_index = int(correct_answer) - 1
                                if not 0 <= correct_index < len(options):
                                    correct_index = 0
                            except ValueError:
                                correct_index = 0

                        if 0 <= correct_index < len(options):
                            st.success(f"**Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„ØµØ­ÙŠØ­Ø©:** {option_letters[correct_index]}. {options[correct_index]}")
                            st.info(f"**Ø§Ù„Ø´Ø±Ø­:** {explanation}")
                        else:
                            st.warning("Ù…Ø¤Ø´Ø± Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø®Ø§Ø±Ø¬ Ø§Ù„Ù†Ø·Ø§Ù‚. Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù„Ù„Ø®ÙŠØ§Ø± Ø§Ù„Ø£ÙˆÙ„.")
                            st.success(f"**Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„ØµØ­ÙŠØ­Ø©:** {option_letters[0]}. {options[0]}")
                            st.info(f"**Ø§Ù„Ø´Ø±Ø­:** {explanation}")
                    except Exception as e:
                        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©: {str(e)}")
                        st.info(f"**Ø§Ù„Ø´Ø±Ø­:** {explanation}")
                
                st.markdown("---")

        # Handle chat responses
        if send_button and user_input:
            try:
                response = rag_manager.generate_answer(user_input)
                bot_answer = response.get("answer", "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¥Ø¬Ø§Ø¨Ø©.")
            except Exception as e:
                bot_answer = f"âŒ Ø®Ø·Ø£: {str(e)}"
            
            # Store conversation
            st.session_state.chat_history.append({"sender": "user", "message": user_input})
            st.session_state.chat_history.append({"sender": "assistant", "message": bot_answer})
            rag_manager.store_conversation(user_input, bot_answer)
            
            # Force refresh to show new messages
            st.rerun()
        
        # Handle deep search
        if search_button and user_input:
            with st.spinner("ğŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… ÙˆØ¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø«..."):
                try:
                    results = search_instance.deep_search(user_input)
                    final_analysis = results["data"].get("finalAnalysis", "Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªØ­Ù„ÙŠÙ„ Ù…ØªØ§Ø­.")
                    sources = results["data"].get("sources", [])

                    # Display results
                    st.subheader("ğŸ“Œ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ:")
                    st.write(final_analysis)

                    st.subheader(f"ğŸ”— Ø§Ù„Ù…ØµØ§Ø¯Ø± ({len(sources)})")
                    for idx, source in enumerate(sources, start=1):
                        st.write(f"{idx}. [{source['title']}]({source['url']})")
                except Exception as e:
                    st.error(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø«: {str(e)}")

        # Display chat history
        display_chat_history()
        st.markdown('</div>', unsafe_allow_html=True)
        
    with tab2:
        st.markdown('<div class="tab-content file-upload-section">', unsafe_allow_html=True)
        st.subheader("ğŸ“¤ Ø±ÙØ¹ Ù…Ù„Ù ÙˆØ·Ø±Ø­ Ø£Ø³Ø¦Ù„Ø© Ø¹Ù„ÙŠÙ‡")
        st.write("ÙŠÙ…ÙƒÙ†Ùƒ Ø±ÙØ¹ Ù…Ø³ØªÙ†Ø¯ Ø¨ØªÙ†Ø³ÙŠÙ‚ PDF ÙˆØ·Ø±Ø­ Ø£Ø³Ø¦Ù„Ø© Ø¹Ù„ÙŠÙ‡ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆØ§Ù‡")
        
        # File uploader
        uploaded_file = st.file_uploader("ğŸ“„ Ù‚Ù… Ø¨Ø±ÙØ¹ Ù…Ù„Ù PDF Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", type=['pdf'])
        
        if uploaded_file is not None:
            # Save the uploaded file temporarily
            temp_file_path = os.path.join(os.getcwd(), uploaded_file.name)
            with open(temp_file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            # Process the file when user clicks the button
            if st.button("âš™ï¸ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³ØªÙ†Ø¯"):
                with st.spinner("ğŸ”„ Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³ØªÙ†Ø¯... Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ Ø°Ù„Ùƒ Ø¨Ø¹Ø¶ Ø§Ù„ÙˆÙ‚Øª."):
                    try:
                        # Use UploadFile to process the document and create vector DB
                        uploader = UploadFile(path=temp_file_path)
                        db_path = uploader.upload()
                        
                        # Update session state with new DB path
                        st.session_state.db_path = db_path
                        st.session_state.collection_name = "new_data"
                        st.session_state.using_uploaded_file = True
                        st.session_state.chat_history = []  # Reset chat history
                        
                        st.success(f"âœ… ØªÙ…Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³ØªÙ†Ø¯ Ø¨Ù†Ø¬Ø§Ø­! ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¢Ù† Ø·Ø±Ø­ Ø£Ø³Ø¦Ù„Ø© Ø¹Ù„ÙŠÙ‡.")
                        st.info("Ø§Ù†ØªÙ‚Ù„ Ø¥Ù„Ù‰ ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ù„Ù„Ø¨Ø¯Ø¡ ÙÙŠ Ø·Ø±Ø­ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³ØªÙ†Ø¯ Ø§Ù„Ø°ÙŠ Ù‚Ù…Øª Ø¨Ø±ÙØ¹Ù‡.")
                    except Exception as e:
                        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³ØªÙ†Ø¯: {str(e)}")
                    finally:
                        # Clean up the temporary file
                        if os.path.exists(temp_file_path):
                            os.remove(temp_file_path)
        st.markdown('</div>', unsafe_allow_html=True)

if __name__ == "__main__":
    main()